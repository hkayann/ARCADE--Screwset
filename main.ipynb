{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da8d1b5",
   "metadata": {},
   "source": [
    "### Intro\n",
    "Train the small model - CIFAR-10 Analysis\n",
    "Which normalization to use, imagenet or cifar10? when fine tuning, I could not find a solid report on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a6625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "==================================================\n",
      "RUNNING EXPERIMENT WITH NORMALIZATION: CIFAR10\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 141/141 [00:15<00:00,  8.99it/s]\n",
      "Epoch 1/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc: 0.8696, Val Acc: 0.8663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.26it/s]\n",
      "Epoch 2/20 [Val]: 100%|██████████| 47/47 [00:04<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Acc: 0.9486, Val Acc: 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.14it/s]\n",
      "Epoch 3/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Acc: 0.9684, Val Acc: 0.9202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.29it/s]\n",
      "Epoch 4/20 [Val]: 100%|██████████| 47/47 [00:04<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Acc: 0.9750, Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Train]: 100%|██████████| 141/141 [00:14<00:00, 10.05it/s]\n",
      "Epoch 5/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Acc: 0.9805, Val Acc: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.19it/s]\n",
      "Epoch 6/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Acc: 0.9832, Val Acc: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Train]: 100%|██████████| 141/141 [00:14<00:00, 10.06it/s]\n",
      "Epoch 7/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Acc: 0.9891, Val Acc: 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.26it/s]\n",
      "Epoch 8/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Acc: 0.9891, Val Acc: 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Train]: 100%|██████████| 141/141 [00:14<00:00, 10.04it/s]\n",
      "Epoch 9/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Acc: 0.9891, Val Acc: 0.9055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.26it/s]\n",
      "Epoch 10/20 [Val]: 100%|██████████| 47/47 [00:04<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Acc: 0.9899, Val Acc: 0.9051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.16it/s]\n",
      "Epoch 11/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Acc: 0.9905, Val Acc: 0.9012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.26it/s]\n",
      "Epoch 12/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Acc: 0.9912, Val Acc: 0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.09it/s]\n",
      "Epoch 13/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Acc: 0.9951, Val Acc: 0.9187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.26it/s]\n",
      "Epoch 14/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Acc: 0.9915, Val Acc: 0.9129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.25it/s]\n",
      "Epoch 15/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Acc: 0.9913, Val Acc: 0.9041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.24it/s]\n",
      "Epoch 16/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Acc: 0.9943, Val Acc: 0.9028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.30it/s]\n",
      "Epoch 17/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Acc: 0.9948, Val Acc: 0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.08it/s]\n",
      "Epoch 18/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Acc: 0.9919, Val Acc: 0.8764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.26it/s]\n",
      "Epoch 19/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Acc: 0.9931, Val Acc: 0.9287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Train]: 100%|██████████| 141/141 [00:14<00:00, 10.01it/s]\n",
      "Epoch 20/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Acc: 0.9945, Val Acc: 0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 47/47 [00:04<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with cifar10! Best Val Acc: 0.9287, Test Acc: 0.9258\n",
      "\n",
      "==================================================\n",
      "RUNNING EXPERIMENT WITH NORMALIZATION: IMAGENET\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.23it/s]\n",
      "Epoch 1/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc: 0.8690, Val Acc: 0.8640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Train]: 100%|██████████| 141/141 [00:14<00:00,  9.91it/s]\n",
      "Epoch 2/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Acc: 0.9480, Val Acc: 0.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.25it/s]\n",
      "Epoch 3/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Acc: 0.9694, Val Acc: 0.8474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.07it/s]\n",
      "Epoch 4/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Acc: 0.9754, Val Acc: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.21it/s]\n",
      "Epoch 5/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Acc: 0.9821, Val Acc: 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.27it/s]\n",
      "Epoch 6/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Acc: 0.9841, Val Acc: 0.8374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Train]: 100%|██████████| 141/141 [00:14<00:00, 10.06it/s]\n",
      "Epoch 7/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Acc: 0.9871, Val Acc: 0.9011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.19it/s]\n",
      "Epoch 8/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Acc: 0.9882, Val Acc: 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Train]: 100%|██████████| 141/141 [00:14<00:00, 10.02it/s]\n",
      "Epoch 9/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Acc: 0.9897, Val Acc: 0.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.26it/s]\n",
      "Epoch 10/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Acc: 0.9907, Val Acc: 0.9156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|██████████| 141/141 [00:14<00:00, 10.04it/s]\n",
      "Epoch 11/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Acc: 0.9901, Val Acc: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.18it/s]\n",
      "Epoch 12/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Acc: 0.9911, Val Acc: 0.9177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|██████████| 141/141 [00:14<00:00,  9.95it/s]\n",
      "Epoch 13/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Acc: 0.9945, Val Acc: 0.9154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.13it/s]\n",
      "Epoch 14/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Acc: 0.9940, Val Acc: 0.8945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Train]: 100%|██████████| 141/141 [00:14<00:00,  9.94it/s]\n",
      "Epoch 15/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Acc: 0.9904, Val Acc: 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.14it/s]\n",
      "Epoch 16/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Acc: 0.9932, Val Acc: 0.9147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.14it/s]\n",
      "Epoch 17/20 [Val]: 100%|██████████| 47/47 [00:04<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Acc: 0.9918, Val Acc: 0.9164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.25it/s]\n",
      "Epoch 18/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Acc: 0.9945, Val Acc: 0.9251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Train]: 100%|██████████| 141/141 [00:13<00:00, 10.20it/s]\n",
      "Epoch 19/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Acc: 0.9946, Val Acc: 0.9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Train]: 100%|██████████| 141/141 [00:14<00:00,  9.95it/s]\n",
      "Epoch 20/20 [Val]: 100%|██████████| 47/47 [00:04<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Acc: 0.9923, Val Acc: 0.8869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 47/47 [00:04<00:00,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with imagenet! Best Val Acc: 0.9251, Test Acc: 0.9267\n",
      "\n",
      "All experiments complete. Combined results saved to /root/arcade/final_scripts/final_results/comparison_results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import MobileNet_V3_Small_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Reproducibility Setup ---\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "# When running on the CuDNN backend, two further options must be set\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = '/root/arcade/data/cifar10_split'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR   = os.path.join(DATA_DIR, 'validation')\n",
    "TEST_DIR  = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "MODEL_DIR   = '/root/arcade/final_scripts/final_models'\n",
    "RESULTS_DIR = '/root/arcade/final_scripts/final_results'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# GPU setup\n",
    "try:\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"GPU not available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using device: {device}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing GPU: {e}\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Main experiment loop ---\n",
    "all_results = []\n",
    "normalization_configs = {\n",
    "    # these are from => https://stackoverflow.com/questions/66678052/how-to-calculate-the-mean-and-the-std-of-cifar10-data\n",
    "    'cifar10': {\n",
    "        'mean': (0.4914, 0.4822, 0.4465),\n",
    "        'std': (0.247, 0.243, 0.261)\n",
    "    },\n",
    "    'imagenet': {\n",
    "        'mean': (0.485, 0.456, 0.406),\n",
    "        'std': (0.229, 0.224, 0.225)\n",
    "    }\n",
    "}\n",
    "\n",
    "RESIZE_DIM = (224, 224)\n",
    "\n",
    "for norm_type, params in normalization_configs.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"RUNNING EXPERIMENT WITH NORMALIZATION: {norm_type.upper()}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "\n",
    "    # 1. Set up transforms for the current experiment\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(RESIZE_DIM),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=params['mean'], std=params['std']),\n",
    "    ])\n",
    "\n",
    "    # 2. Create datasets and dataloaders\n",
    "    train_ds = datasets.ImageFolder(TRAIN_DIR, transform=transform)\n",
    "    val_ds   = datasets.ImageFolder(VAL_DIR,   transform=transform)\n",
    "    test_ds  = datasets.ImageFolder(TEST_DIR,  transform=transform)\n",
    "\n",
    "    BATCH_SIZE = 256\n",
    "    NUM_WORKERS = 4\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    # 3. Re-initialize the model and optimizer to start fresh\n",
    "    weights = MobileNet_V3_Small_Weights.DEFAULT\n",
    "    model = models.mobilenet_v3_small(weights=weights)\n",
    "    in_feats = model.classifier[3].in_features\n",
    "    model.classifier[3] = nn.Linear(in_feats, len(train_ds.classes))\n",
    "    model = model.to(device)\n",
    "\n",
    "    LR = 1e-3\n",
    "    NUM_EPOCHS = 20\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    history = []\n",
    "\n",
    "    # 4. Training loop\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        for inputs, targets in tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} [Train]\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "        train_loss /= total\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(val_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} [Val]\"):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += preds.eq(targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "        val_loss /= total\n",
    "        val_acc = correct / total\n",
    "\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'train_acc': train_acc, 'val_loss': val_loss, 'val_acc': val_acc})\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_DIR, f'best_model_{norm_type}.pth'))\n",
    "        print(f\"Epoch {epoch}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # 5. Load best model and test\n",
    "    model.load_state_dict(torch.load(os.path.join(MODEL_DIR, f'best_model_{norm_type}.pth')))\n",
    "    model.eval()\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "    test_loss /= total\n",
    "    test_acc = correct / total\n",
    "    \n",
    "    print(f\"\\nDone with {norm_type}! Best Val Acc: {best_val_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    # 6. Store results for this run\n",
    "    results = {\n",
    "        'normalization_type': norm_type,\n",
    "        'resize_size': list(RESIZE_DIM), # Added this line\n",
    "        'normalization_mean': params['mean'],\n",
    "        'normalization_std': params['std'],\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'test_loss': test_loss,\n",
    "        'test_acc': test_acc,\n",
    "        'history': history,\n",
    "        'model_details': {\n",
    "            'model': 'mobilenet_v3_small',\n",
    "            'weights': 'MobileNet_V3_Small_Weights.DEFAULT',\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'learning_rate': LR,\n",
    "            'num_epochs': NUM_EPOCHS,\n",
    "            'optimizer': 'Adam',\n",
    "            'seed': SEED\n",
    "        }\n",
    "    }\n",
    "    all_results.append(results)\n",
    "\n",
    "# 7. Save all combined results to a single JSON file\n",
    "output_file = os.path.join(RESULTS_DIR, 'normalization_compar.json')\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(all_results, f, indent=4)\n",
    "\n",
    "print(f\"\\nAll experiments complete. Combined results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae01525",
   "metadata": {},
   "source": [
    "- Imagenet Normalization is better, we should go with that one.\n",
    "- Model path is: /root/arcade/final_scripts/final_models/best_model_imagenet.pth\n",
    "\n",
    "We evalaute the baseline performance on cifar-10-c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c431925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import json # <-- Added this import\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -- Step 1: Set the correct path and normalization --\n",
    "MODEL_PATH = '/root/arcade/final_scripts/final_models/best_model_imagenet.pth'\n",
    "NORMALIZATION = {\n",
    "    'mean': [0.485, 0.456, 0.406],\n",
    "    'std': [0.229, 0.224, 0.225]\n",
    "}\n",
    "\n",
    "# --- Other Parameters ---\n",
    "CIFAR_C_DIR = '/root/arcade/data/CIFAR-10-C'\n",
    "RESULTS_DIR = '/root/arcade/final_scripts/final_results' # <-- Added results path\n",
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 4\n",
    "RESIZE_DIM = (224, 224)\n",
    "\n",
    "# GPU setup\n",
    "try:\n",
    "    if not torch.cuda.is_available():\n",
    "        raise RuntimeError(\"GPU not available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using device: {device}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing GPU: {e}\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Define a custom Dataset for .npy files ---\n",
    "class CustomNumpyDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading data from numpy arrays\"\"\"\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = torch.from_numpy(labels).long()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = transforms.ToPILImage()(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# --- Prepare Model ---\n",
    "model = models.mobilenet_v3_small(weights=None)\n",
    "in_feats = model.classifier[3].in_features\n",
    "model.classifier[3] = torch.nn.Linear(in_feats, 10)\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(f\"Error: Model path not found at {MODEL_PATH}\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "    \n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(f\"Model loaded from {MODEL_PATH}\")\n",
    "\n",
    "# --- Prepare Data Transforms ---\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(RESIZE_DIM),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORMALIZATION['mean'], std=NORMALIZATION['std']),\n",
    "])\n",
    "\n",
    "# --- Evaluation Loop ---\n",
    "labels_path = os.path.join(CIFAR_C_DIR, 'labels.npy')\n",
    "if not os.path.exists(labels_path):\n",
    "    print(f\"Error: labels.npy not found in {CIFAR_C_DIR}\", file=sys.stderr)\n",
    "    sys.exit(1)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "corruption_files = [f for f in os.listdir(CIFAR_C_DIR) if f.endswith('.npy') and f != 'labels.npy']\n",
    "corruption_results = {}\n",
    "\n",
    "print(\"\\nStarting evaluation on CIFAR-10-C corruptions...\")\n",
    "\n",
    "for corruption_file in sorted(corruption_files):\n",
    "    images_path = os.path.join(CIFAR_C_DIR, corruption_file)\n",
    "    images = np.load(images_path)\n",
    "    \n",
    "    dataset = CustomNumpyDataset(images, labels, transform=eval_transform)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(loader, desc=f\"Testing {corruption_file.replace('.npy', '')}\"):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "    accuracy = 100 * correct / total\n",
    "    corruption_results[corruption_file.replace('.npy', '')] = accuracy\n",
    "\n",
    "# --- Print Final Results ---\n",
    "print(\"\\n--- CIFAR-10-C Evaluation Results ---\")\n",
    "for corruption_type, acc in corruption_results.items():\n",
    "    print(f\"{corruption_type:<20} | Accuracy: {acc:.2f}%\")\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "# --- Save results to JSON file --- # <-- ADDED THIS ENTIRE BLOCK\n",
    "final_output = {\n",
    "    'model_evaluated': MODEL_PATH,\n",
    "    'evaluation_dataset': 'CIFAR-10-C',\n",
    "    'corruption_accuracies': corruption_results\n",
    "}\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "output_filepath = os.path.join(RESULTS_DIR, 'cifar_c_results.json')\n",
    "with open(output_filepath, 'w') as f:\n",
    "    json.dump(final_output, f, indent=4)\n",
    "\n",
    "print(f\"\\nEvaluation results saved to {output_filepath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
